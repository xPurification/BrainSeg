{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np \n",
    "import cv2\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from albumentations import HorizontalFlip, CoarseDropout, RandomBrightnessContrast, RandomRotate90\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PYTHONHASHSEED\"]= str(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=8\n",
    "lr=0.0001\n",
    "epoch=100\n",
    "height=128\n",
    "width=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = os.path.join(\"dataset2\", \"non-aug\")\n",
    "files_dir= os.path.join(\"files\", \"non-aug\")\n",
    "model_file=os.path.join(files_dir, \"unet-non-aug.h5\")\n",
    "log_file=os.path.join(files_dir, \"log-non-aug.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "create_dir(files_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(inputs, num_filters):\n",
    "    x= Conv2D(num_filters, 3, padding=\"same\")(inputs)\n",
    "    x= BatchNormalization()(x)\n",
    "    x=Activation('relu')(x)\n",
    "\n",
    "    x=Conv2D(num_filters, 3, padding=\"same\")(x)\n",
    "    x=BatchNormalization()(x)\n",
    "    x=Activation(\"relu\")(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_block(inputs, num_filters):\n",
    "    x= conv_block(inputs, num_filters)\n",
    "    p=MaxPool2D((2,2))(x)\n",
    "    return x,p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_block(inputs, skip, num_filters):\n",
    "    x=Conv2DTranspose(num_filters, (2,2), strides=2, padding=\"same\")(inputs)\n",
    "    x= Concatenate()([x,skip])\n",
    "    x= conv_block(x,num_filters)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_unet(input_shape):\n",
    "    inputs =Input(input_shape)\n",
    "    s1,p1=encoder_block(inputs,64)\n",
    "    s2,p2=encoder_block(p1, 128)\n",
    "    s3,p3=encoder_block(p2,512)\n",
    "    s4,p4=encoder_block(p3,512)\n",
    "    b1= conv_block(p4, 1024)\n",
    "\n",
    "    d1=decoder_block(b1,s4,512)\n",
    "    d2=decoder_block(d1,s3,256)\n",
    "    d3=decoder_block(d2,s2,128)\n",
    "    d4=decoder_block(d3,s1,64)\n",
    "    outputs= Conv2D(1,1, padding=\"same\", activation=\"sigmoid\")(d4)\n",
    "    model= Model(inputs, outputs, name=\"UNET\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    train_x= sorted(glob(os.path.join(path, \"train\", \"images\", \"*\" )))\n",
    "    train_y= sorted(glob(os.path.join(path, \"train\", \"masks\", \"*\" )))\n",
    "    test = sorted(glob(os.path.join(path, \"test\", \"*\" )))\n",
    "    valid_x= sorted(glob(os.path.join(path, \"valid\", \"images\", \"*\" )))\n",
    "    valid_y= sorted(glob(os.path.join(path, \"valid\", \"masks\", \"*\" )))\n",
    "\n",
    "    return (train_x, train_y), (valid_x, valid_y) , test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(path):\n",
    "    path=path.decode()\n",
    "    x=cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    x=x/255.0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_mask(path):\n",
    "    path=path.decode()\n",
    "    x=cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    x=x/255.0\n",
    "    x=np.expand_dims(x,axis=-1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_parse(x,y):\n",
    "    def _parse(x,y):\n",
    "        x= read_image(x)\n",
    "        y= read_mask(y)\n",
    "        return x,y\n",
    "    x,y =tf.numpy_function(_parse, [x,y], [tf.float64,tf.float64])\n",
    "    x.set_shape([height, width, 3])\n",
    "    y.set_shape([height, width, 1])\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_dataset(x,y, batch=8):\n",
    "    dataset= tf.data.Dataset.from_tensor_slices((x,y))\n",
    "    dataset= dataset.map(tf_parse,num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset=dataset.batch(batch)\n",
    "    dataset= dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 1195 1195\n",
      "valid 239 239\n",
      "test 2\n"
     ]
    }
   ],
   "source": [
    "(train_x, train_y), (valid_x, valid_y),test= load_data(dataset_path)\n",
    "\n",
    "print(\"train\" , len(train_x), len(train_y))\n",
    "print(\"valid\" , len(valid_x), len(valid_y))\n",
    "print(\"test\" , len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_dataset= tf_dataset(train_x, train_y, batch=batch_size)\n",
    "valid_dataset= tf_dataset(valid_x, valid_y, batch=batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (height, width, 3)\n",
    "model= build_unet(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"UNET\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 128, 128, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 128, 128, 64  1792        ['input_3[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 128, 128, 64  256        ['conv2d_38[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 128, 128, 64  0           ['batch_normalization_36[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 128, 128, 64  36928       ['activation_36[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 128, 128, 64  256        ['conv2d_39[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 128, 128, 64  0           ['batch_normalization_37[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_8 (MaxPooling2D)  (None, 64, 64, 64)  0           ['activation_37[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 64, 64, 128)  73856       ['max_pooling2d_8[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 64, 64, 128)  512        ['conv2d_40[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (None, 64, 64, 128)  0           ['batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 64, 64, 128)  147584      ['activation_38[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 64, 64, 128)  512        ['conv2d_41[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_39 (Activation)     (None, 64, 64, 128)  0           ['batch_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_9 (MaxPooling2D)  (None, 32, 32, 128)  0          ['activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 32, 32, 512)  590336      ['max_pooling2d_9[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 32, 32, 512)  2048       ['conv2d_42[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_40 (Activation)     (None, 32, 32, 512)  0           ['batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 32, 32, 512)  2359808     ['activation_40[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 32, 32, 512)  2048       ['conv2d_43[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_41 (Activation)     (None, 32, 32, 512)  0           ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_10 (MaxPooling2D  (None, 16, 16, 512)  0          ['activation_41[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 16, 16, 512)  2359808     ['max_pooling2d_10[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 16, 16, 512)  2048       ['conv2d_44[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, 16, 16, 512)  0           ['batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 16, 16, 512)  2359808     ['activation_42[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 16, 16, 512)  2048       ['conv2d_45[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, 16, 16, 512)  0           ['batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_11 (MaxPooling2D  (None, 8, 8, 512)   0           ['activation_43[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 8, 8, 1024)   4719616     ['max_pooling2d_11[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 8, 8, 1024)  4096        ['conv2d_46[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, 8, 8, 1024)   0           ['batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 8, 8, 1024)   9438208     ['activation_44[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 8, 8, 1024)  4096        ['conv2d_47[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_45 (Activation)     (None, 8, 8, 1024)   0           ['batch_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_transpose_8 (Conv2DTran  (None, 16, 16, 512)  2097664    ['activation_45[0][0]']          \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate)    (None, 16, 16, 1024  0           ['conv2d_transpose_8[0][0]',     \n",
      "                                )                                 'activation_43[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 16, 16, 512)  4719104     ['concatenate_8[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 16, 16, 512)  2048       ['conv2d_48[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_46 (Activation)     (None, 16, 16, 512)  0           ['batch_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 16, 16, 512)  2359808     ['activation_46[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 16, 16, 512)  2048       ['conv2d_49[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_47 (Activation)     (None, 16, 16, 512)  0           ['batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_transpose_9 (Conv2DTran  (None, 32, 32, 256)  524544     ['activation_47[0][0]']          \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_9 (Concatenate)    (None, 32, 32, 768)  0           ['conv2d_transpose_9[0][0]',     \n",
      "                                                                  'activation_41[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 32, 32, 256)  1769728     ['concatenate_9[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_50[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_48 (Activation)     (None, 32, 32, 256)  0           ['batch_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, 32, 32, 256)  590080      ['activation_48[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_51[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_49 (Activation)     (None, 32, 32, 256)  0           ['batch_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_transpose_10 (Conv2DTra  (None, 64, 64, 128)  131200     ['activation_49[0][0]']          \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate_10 (Concatenate)   (None, 64, 64, 256)  0           ['conv2d_transpose_10[0][0]',    \n",
      "                                                                  'activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, 64, 64, 128)  295040      ['concatenate_10[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 64, 64, 128)  512        ['conv2d_52[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_50 (Activation)     (None, 64, 64, 128)  0           ['batch_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, 64, 64, 128)  147584      ['activation_50[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 64, 64, 128)  512        ['conv2d_53[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_51 (Activation)     (None, 64, 64, 128)  0           ['batch_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_transpose_11 (Conv2DTra  (None, 128, 128, 64  32832      ['activation_51[0][0]']          \n",
      " nspose)                        )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_11 (Concatenate)   (None, 128, 128, 12  0           ['conv2d_transpose_11[0][0]',    \n",
      "                                8)                                'activation_37[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, 128, 128, 64  73792       ['concatenate_11[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 128, 128, 64  256        ['conv2d_54[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_52 (Activation)     (None, 128, 128, 64  0           ['batch_normalization_52[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, 128, 128, 64  36928       ['activation_52[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_53 (BatchN  (None, 128, 128, 64  256        ['conv2d_55[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_53 (Activation)     (None, 128, 128, 64  0           ['batch_normalization_53[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)             (None, 128, 128, 1)  65          ['activation_53[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 34,891,713\n",
      "Trainable params: 34,878,913\n",
      "Non-trainable params: 12,800\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "\n",
    "opt=tf.keras.optimizers.Adam(lr)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks=[\n",
    "\n",
    "    ModelCheckpoint(model_file, verbose=1, save_best_only=True), \n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=.1, patience=4),\n",
    "    CSVLogger(log_file), \n",
    "    EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=False)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - ETA: 0s - loss: 0.3456 - accuracy: 0.9315\n",
      "Epoch 1: val_loss improved from inf to 0.55076, saving model to files/non-aug/unet-non-aug.h5\n",
      "150/150 [==============================] - 21s 128ms/step - loss: 0.3456 - accuracy: 0.9315 - val_loss: 0.5508 - val_accuracy: 0.8833 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.2471 - accuracy: 0.9327\n",
      "Epoch 2: val_loss improved from 0.55076 to 0.36001, saving model to files/non-aug/unet-non-aug.h5\n",
      "150/150 [==============================] - 17s 110ms/step - loss: 0.2471 - accuracy: 0.9327 - val_loss: 0.3600 - val_accuracy: 0.8914 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.2104 - accuracy: 0.9361\n",
      "Epoch 3: val_loss improved from 0.36001 to 0.32428, saving model to files/non-aug/unet-non-aug.h5\n",
      "150/150 [==============================] - 16s 109ms/step - loss: 0.2104 - accuracy: 0.9361 - val_loss: 0.3243 - val_accuracy: 0.8914 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.1860 - accuracy: 0.9415\n",
      "Epoch 4: val_loss improved from 0.32428 to 0.31531, saving model to files/non-aug/unet-non-aug.h5\n",
      "150/150 [==============================] - 16s 107ms/step - loss: 0.1860 - accuracy: 0.9415 - val_loss: 0.3153 - val_accuracy: 0.8927 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1696 - accuracy: 0.9469\n",
      "Epoch 5: val_loss improved from 0.31531 to 0.27373, saving model to files/non-aug/unet-non-aug.h5\n",
      "150/150 [==============================] - 16s 107ms/step - loss: 0.1696 - accuracy: 0.9468 - val_loss: 0.2737 - val_accuracy: 0.8922 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1482 - accuracy: 0.9534\n",
      "Epoch 6: val_loss improved from 0.27373 to 0.24792, saving model to files/non-aug/unet-non-aug.h5\n",
      "150/150 [==============================] - 16s 105ms/step - loss: 0.1483 - accuracy: 0.9533 - val_loss: 0.2479 - val_accuracy: 0.8931 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1335 - accuracy: 0.9583\n",
      "Epoch 7: val_loss did not improve from 0.24792\n",
      "150/150 [==============================] - 15s 99ms/step - loss: 0.1336 - accuracy: 0.9582 - val_loss: 0.2494 - val_accuracy: 0.8931 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1175 - accuracy: 0.9636\n",
      "Epoch 8: val_loss did not improve from 0.24792\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.1176 - accuracy: 0.9635 - val_loss: 0.2696 - val_accuracy: 0.8914 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.1058 - accuracy: 0.9671\n",
      "Epoch 9: val_loss improved from 0.24792 to 0.23723, saving model to files/non-aug/unet-non-aug.h5\n",
      "150/150 [==============================] - 16s 104ms/step - loss: 0.1059 - accuracy: 0.9669 - val_loss: 0.2372 - val_accuracy: 0.8944 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.0998 - accuracy: 0.9682\n",
      "Epoch 10: val_loss did not improve from 0.23723\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.1000 - accuracy: 0.9680 - val_loss: 0.2535 - val_accuracy: 0.8929 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.0915 - accuracy: 0.9705\n",
      "Epoch 11: val_loss improved from 0.23723 to 0.17672, saving model to files/non-aug/unet-non-aug.h5\n",
      "150/150 [==============================] - 16s 105ms/step - loss: 0.0917 - accuracy: 0.9703 - val_loss: 0.1767 - val_accuracy: 0.9029 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0816 - accuracy: 0.9738\n",
      "Epoch 12: val_loss improved from 0.17672 to 0.15727, saving model to files/non-aug/unet-non-aug.h5\n",
      "150/150 [==============================] - 16s 106ms/step - loss: 0.0816 - accuracy: 0.9738 - val_loss: 0.1573 - val_accuracy: 0.9149 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.0716 - accuracy: 0.9775\n",
      "Epoch 13: val_loss improved from 0.15727 to 0.14377, saving model to files/non-aug/unet-non-aug.h5\n",
      "150/150 [==============================] - 16s 106ms/step - loss: 0.0717 - accuracy: 0.9774 - val_loss: 0.1438 - val_accuracy: 0.9301 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.0622 - accuracy: 0.9807\n",
      "Epoch 14: val_loss did not improve from 0.14377\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.0623 - accuracy: 0.9806 - val_loss: 0.1486 - val_accuracy: 0.9317 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0560 - accuracy: 0.9828\n",
      "Epoch 15: val_loss did not improve from 0.14377\n",
      "150/150 [==============================] - 15s 102ms/step - loss: 0.0560 - accuracy: 0.9828 - val_loss: 0.1495 - val_accuracy: 0.9418 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.0497 - accuracy: 0.9847\n",
      "Epoch 16: val_loss improved from 0.14377 to 0.14136, saving model to files/non-aug/unet-non-aug.h5\n",
      "150/150 [==============================] - 16s 107ms/step - loss: 0.0498 - accuracy: 0.9846 - val_loss: 0.1414 - val_accuracy: 0.9284 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.0459 - accuracy: 0.9855\n",
      "Epoch 17: val_loss did not improve from 0.14136\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.0460 - accuracy: 0.9854 - val_loss: 0.2297 - val_accuracy: 0.8971 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0457 - accuracy: 0.9851\n",
      "Epoch 18: val_loss did not improve from 0.14136\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.0457 - accuracy: 0.9851 - val_loss: 0.1537 - val_accuracy: 0.9155 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.0407 - accuracy: 0.9868\n",
      "Epoch 19: val_loss did not improve from 0.14136\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.0407 - accuracy: 0.9868 - val_loss: 0.1645 - val_accuracy: 0.9323 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.0390 - accuracy: 0.9870\n",
      "Epoch 20: val_loss did not improve from 0.14136\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.0390 - accuracy: 0.9870 - val_loss: 0.1701 - val_accuracy: 0.9068 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.0414 - accuracy: 0.9863\n",
      "Epoch 21: val_loss improved from 0.14136 to 0.08304, saving model to files/non-aug/unet-non-aug.h5\n",
      "150/150 [==============================] - 16s 106ms/step - loss: 0.0414 - accuracy: 0.9863 - val_loss: 0.0830 - val_accuracy: 0.9713 - lr: 1.0000e-05\n",
      "Epoch 22/100\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.0346 - accuracy: 0.9884\n",
      "Epoch 22: val_loss improved from 0.08304 to 0.07074, saving model to files/non-aug/unet-non-aug.h5\n",
      "150/150 [==============================] - 16s 106ms/step - loss: 0.0346 - accuracy: 0.9884 - val_loss: 0.0707 - val_accuracy: 0.9769 - lr: 1.0000e-05\n",
      "Epoch 23/100\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.0323 - accuracy: 0.9892\n",
      "Epoch 23: val_loss improved from 0.07074 to 0.06495, saving model to files/non-aug/unet-non-aug.h5\n",
      "150/150 [==============================] - 16s 105ms/step - loss: 0.0323 - accuracy: 0.9892 - val_loss: 0.0649 - val_accuracy: 0.9783 - lr: 1.0000e-05\n",
      "Epoch 24/100\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.0310 - accuracy: 0.9897\n",
      "Epoch 24: val_loss improved from 0.06495 to 0.06115, saving model to files/non-aug/unet-non-aug.h5\n",
      "150/150 [==============================] - 16s 105ms/step - loss: 0.0310 - accuracy: 0.9898 - val_loss: 0.0612 - val_accuracy: 0.9794 - lr: 1.0000e-05\n",
      "Epoch 25/100\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0299 - accuracy: 0.9902\n",
      "Epoch 25: val_loss improved from 0.06115 to 0.05891, saving model to files/non-aug/unet-non-aug.h5\n",
      "150/150 [==============================] - 16s 106ms/step - loss: 0.0299 - accuracy: 0.9902 - val_loss: 0.0589 - val_accuracy: 0.9800 - lr: 1.0000e-05\n",
      "Epoch 26/100\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.0291 - accuracy: 0.9905\n",
      "Epoch 26: val_loss improved from 0.05891 to 0.05751, saving model to files/non-aug/unet-non-aug.h5\n",
      "150/150 [==============================] - 16s 106ms/step - loss: 0.0291 - accuracy: 0.9905 - val_loss: 0.0575 - val_accuracy: 0.9803 - lr: 1.0000e-05\n",
      "Epoch 27/100\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.0283 - accuracy: 0.9909\n",
      "Epoch 27: val_loss improved from 0.05751 to 0.05669, saving model to files/non-aug/unet-non-aug.h5\n",
      "150/150 [==============================] - 16s 106ms/step - loss: 0.0283 - accuracy: 0.9908 - val_loss: 0.0567 - val_accuracy: 0.9805 - lr: 1.0000e-05\n",
      "Epoch 28/100\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0276 - accuracy: 0.9911\n",
      "Epoch 28: val_loss improved from 0.05669 to 0.05565, saving model to files/non-aug/unet-non-aug.h5\n",
      "150/150 [==============================] - 16s 106ms/step - loss: 0.0276 - accuracy: 0.9911 - val_loss: 0.0557 - val_accuracy: 0.9807 - lr: 1.0000e-05\n",
      "Epoch 29/100\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0270 - accuracy: 0.9913\n",
      "Epoch 29: val_loss improved from 0.05565 to 0.05469, saving model to files/non-aug/unet-non-aug.h5\n",
      "150/150 [==============================] - 16s 106ms/step - loss: 0.0270 - accuracy: 0.9913 - val_loss: 0.0547 - val_accuracy: 0.9811 - lr: 1.0000e-05\n",
      "Epoch 30/100\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0263 - accuracy: 0.9916\n",
      "Epoch 30: val_loss improved from 0.05469 to 0.05375, saving model to files/non-aug/unet-non-aug.h5\n",
      "150/150 [==============================] - 16s 105ms/step - loss: 0.0263 - accuracy: 0.9916 - val_loss: 0.0538 - val_accuracy: 0.9814 - lr: 1.0000e-05\n",
      "Epoch 31/100\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0258 - accuracy: 0.9918\n",
      "Epoch 31: val_loss improved from 0.05375 to 0.05245, saving model to files/non-aug/unet-non-aug.h5\n",
      "150/150 [==============================] - 16s 106ms/step - loss: 0.0258 - accuracy: 0.9918 - val_loss: 0.0524 - val_accuracy: 0.9820 - lr: 1.0000e-05\n",
      "Epoch 32/100\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.0252 - accuracy: 0.9920\n",
      "Epoch 32: val_loss improved from 0.05245 to 0.05126, saving model to files/non-aug/unet-non-aug.h5\n",
      "150/150 [==============================] - 16s 106ms/step - loss: 0.0252 - accuracy: 0.9919 - val_loss: 0.0513 - val_accuracy: 0.9824 - lr: 1.0000e-05\n",
      "Epoch 33/100\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.0247 - accuracy: 0.9921\n",
      "Epoch 33: val_loss improved from 0.05126 to 0.05014, saving model to files/non-aug/unet-non-aug.h5\n",
      "150/150 [==============================] - 16s 107ms/step - loss: 0.0247 - accuracy: 0.9921 - val_loss: 0.0501 - val_accuracy: 0.9829 - lr: 1.0000e-05\n",
      "Epoch 34/100\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.0242 - accuracy: 0.9923\n",
      "Epoch 34: val_loss improved from 0.05014 to 0.04886, saving model to files/non-aug/unet-non-aug.h5\n",
      "150/150 [==============================] - 16s 109ms/step - loss: 0.0242 - accuracy: 0.9923 - val_loss: 0.0489 - val_accuracy: 0.9834 - lr: 1.0000e-05\n",
      "Epoch 35/100\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.0237 - accuracy: 0.9924\n",
      "Epoch 35: val_loss improved from 0.04886 to 0.04777, saving model to files/non-aug/unet-non-aug.h5\n",
      "150/150 [==============================] - 16s 106ms/step - loss: 0.0237 - accuracy: 0.9924 - val_loss: 0.0478 - val_accuracy: 0.9838 - lr: 1.0000e-05\n",
      "Epoch 36/100\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.0233 - accuracy: 0.9926\n",
      "Epoch 36: val_loss improved from 0.04777 to 0.04668, saving model to files/non-aug/unet-non-aug.h5\n",
      "150/150 [==============================] - 16s 107ms/step - loss: 0.0233 - accuracy: 0.9926 - val_loss: 0.0467 - val_accuracy: 0.9841 - lr: 1.0000e-05\n",
      "Epoch 37/100\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.0229 - accuracy: 0.9927\n",
      "Epoch 37: val_loss improved from 0.04668 to 0.04564, saving model to files/non-aug/unet-non-aug.h5\n",
      "150/150 [==============================] - 16s 106ms/step - loss: 0.0229 - accuracy: 0.9927 - val_loss: 0.0456 - val_accuracy: 0.9845 - lr: 1.0000e-05\n",
      "Epoch 38/100\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.0224 - accuracy: 0.9929\n",
      "Epoch 38: val_loss improved from 0.04564 to 0.04482, saving model to files/non-aug/unet-non-aug.h5\n",
      "150/150 [==============================] - 16s 106ms/step - loss: 0.0224 - accuracy: 0.9929 - val_loss: 0.0448 - val_accuracy: 0.9849 - lr: 1.0000e-05\n",
      "Epoch 39/100\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.0220 - accuracy: 0.9930\n",
      "Epoch 39: val_loss improved from 0.04482 to 0.04404, saving model to files/non-aug/unet-non-aug.h5\n",
      "150/150 [==============================] - 16s 106ms/step - loss: 0.0220 - accuracy: 0.9930 - val_loss: 0.0440 - val_accuracy: 0.9853 - lr: 1.0000e-05\n",
      "Epoch 40/100\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0216 - accuracy: 0.9931\n",
      "Epoch 40: val_loss improved from 0.04404 to 0.04320, saving model to files/non-aug/unet-non-aug.h5\n",
      "150/150 [==============================] - 16s 108ms/step - loss: 0.0216 - accuracy: 0.9931 - val_loss: 0.0432 - val_accuracy: 0.9856 - lr: 1.0000e-05\n",
      "Epoch 41/100\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0212 - accuracy: 0.9932\n",
      "Epoch 41: val_loss improved from 0.04320 to 0.04242, saving model to files/non-aug/unet-non-aug.h5\n",
      "150/150 [==============================] - 16s 107ms/step - loss: 0.0212 - accuracy: 0.9932 - val_loss: 0.0424 - val_accuracy: 0.9859 - lr: 1.0000e-05\n",
      "Epoch 42/100\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.0207 - accuracy: 0.9934\n",
      "Epoch 42: val_loss improved from 0.04242 to 0.04140, saving model to files/non-aug/unet-non-aug.h5\n",
      "150/150 [==============================] - 16s 106ms/step - loss: 0.0207 - accuracy: 0.9934 - val_loss: 0.0414 - val_accuracy: 0.9863 - lr: 1.0000e-05\n",
      "Epoch 43/100\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.0203 - accuracy: 0.9935\n",
      "Epoch 43: val_loss improved from 0.04140 to 0.04038, saving model to files/non-aug/unet-non-aug.h5\n",
      "150/150 [==============================] - 30s 203ms/step - loss: 0.0203 - accuracy: 0.9935 - val_loss: 0.0404 - val_accuracy: 0.9866 - lr: 1.0000e-05\n",
      "Epoch 44/100\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0199 - accuracy: 0.9936\n",
      "Epoch 44: val_loss improved from 0.04038 to 0.03953, saving model to files/non-aug/unet-non-aug.h5\n",
      "150/150 [==============================] - 17s 112ms/step - loss: 0.0199 - accuracy: 0.9936 - val_loss: 0.0395 - val_accuracy: 0.9869 - lr: 1.0000e-05\n",
      "Epoch 45/100\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0195 - accuracy: 0.9937\n",
      "Epoch 45: val_loss improved from 0.03953 to 0.03905, saving model to files/non-aug/unet-non-aug.h5\n",
      "150/150 [==============================] - 17s 113ms/step - loss: 0.0195 - accuracy: 0.9937 - val_loss: 0.0390 - val_accuracy: 0.9871 - lr: 1.0000e-05\n",
      "Epoch 46/100\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0191 - accuracy: 0.9938\n",
      "Epoch 46: val_loss improved from 0.03905 to 0.03851, saving model to files/non-aug/unet-non-aug.h5\n",
      "150/150 [==============================] - 20s 136ms/step - loss: 0.0191 - accuracy: 0.9938 - val_loss: 0.0385 - val_accuracy: 0.9872 - lr: 1.0000e-05\n",
      "Epoch 47/100\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0187 - accuracy: 0.9940\n",
      "Epoch 47: val_loss improved from 0.03851 to 0.03794, saving model to files/non-aug/unet-non-aug.h5\n",
      "150/150 [==============================] - 19s 123ms/step - loss: 0.0187 - accuracy: 0.9940 - val_loss: 0.0379 - val_accuracy: 0.9874 - lr: 1.0000e-05\n",
      "Epoch 48/100\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0183 - accuracy: 0.9941\n",
      "Epoch 48: val_loss improved from 0.03794 to 0.03689, saving model to files/non-aug/unet-non-aug.h5\n",
      "150/150 [==============================] - 16s 105ms/step - loss: 0.0183 - accuracy: 0.9941 - val_loss: 0.0369 - val_accuracy: 0.9877 - lr: 1.0000e-05\n",
      "Epoch 49/100\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0179 - accuracy: 0.9942\n",
      "Epoch 49: val_loss improved from 0.03689 to 0.03641, saving model to files/non-aug/unet-non-aug.h5\n",
      "150/150 [==============================] - 17s 115ms/step - loss: 0.0179 - accuracy: 0.9942 - val_loss: 0.0364 - val_accuracy: 0.9879 - lr: 1.0000e-05\n",
      "Epoch 50/100\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0175 - accuracy: 0.9943\n",
      "Epoch 50: val_loss improved from 0.03641 to 0.03492, saving model to files/non-aug/unet-non-aug.h5\n",
      "150/150 [==============================] - 17s 111ms/step - loss: 0.0175 - accuracy: 0.9943 - val_loss: 0.0349 - val_accuracy: 0.9883 - lr: 1.0000e-05\n",
      "Epoch 51/100\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0171 - accuracy: 0.9945\n",
      "Epoch 51: val_loss did not improve from 0.03492\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.0171 - accuracy: 0.9945 - val_loss: 0.0352 - val_accuracy: 0.9884 - lr: 1.0000e-05\n",
      "Epoch 52/100\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.0171 - accuracy: 0.9944\n",
      "Epoch 52: val_loss improved from 0.03492 to 0.03262, saving model to files/non-aug/unet-non-aug.h5\n",
      "150/150 [==============================] - 16s 107ms/step - loss: 0.0171 - accuracy: 0.9944 - val_loss: 0.0326 - val_accuracy: 0.9890 - lr: 1.0000e-05\n",
      "Epoch 53/100\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0168 - accuracy: 0.9946\n",
      "Epoch 53: val_loss did not improve from 0.03262\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.0168 - accuracy: 0.9946 - val_loss: 0.0367 - val_accuracy: 0.9879 - lr: 1.0000e-05\n",
      "Epoch 54/100\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.0168 - accuracy: 0.9945\n",
      "Epoch 54: val_loss improved from 0.03262 to 0.03221, saving model to files/non-aug/unet-non-aug.h5\n",
      "150/150 [==============================] - 16s 108ms/step - loss: 0.0168 - accuracy: 0.9945 - val_loss: 0.0322 - val_accuracy: 0.9893 - lr: 1.0000e-05\n",
      "Epoch 55/100\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.0159 - accuracy: 0.9949\n",
      "Epoch 55: val_loss improved from 0.03221 to 0.03136, saving model to files/non-aug/unet-non-aug.h5\n",
      "150/150 [==============================] - 16s 108ms/step - loss: 0.0159 - accuracy: 0.9949 - val_loss: 0.0314 - val_accuracy: 0.9897 - lr: 1.0000e-05\n",
      "Epoch 56/100\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0156 - accuracy: 0.9950\n",
      "Epoch 56: val_loss did not improve from 0.03136\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.0156 - accuracy: 0.9950 - val_loss: 0.0324 - val_accuracy: 0.9894 - lr: 1.0000e-05\n",
      "Epoch 57/100\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.0154 - accuracy: 0.9950\n",
      "Epoch 57: val_loss did not improve from 0.03136\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.0154 - accuracy: 0.9950 - val_loss: 0.0321 - val_accuracy: 0.9895 - lr: 1.0000e-05\n",
      "Epoch 58/100\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.0152 - accuracy: 0.9950\n",
      "Epoch 58: val_loss did not improve from 0.03136\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.0152 - accuracy: 0.9950 - val_loss: 0.0315 - val_accuracy: 0.9897 - lr: 1.0000e-05\n",
      "Epoch 59/100\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.0149 - accuracy: 0.9951\n",
      "Epoch 59: val_loss did not improve from 0.03136\n",
      "150/150 [==============================] - 15s 102ms/step - loss: 0.0149 - accuracy: 0.9951 - val_loss: 0.0330 - val_accuracy: 0.9894 - lr: 1.0000e-05\n",
      "Epoch 60/100\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.0149 - accuracy: 0.9951\n",
      "Epoch 60: val_loss did not improve from 0.03136\n",
      "150/150 [==============================] - 15s 102ms/step - loss: 0.0149 - accuracy: 0.9951 - val_loss: 0.0340 - val_accuracy: 0.9892 - lr: 1.0000e-06\n",
      "Epoch 61/100\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.0144 - accuracy: 0.9953\n",
      "Epoch 61: val_loss did not improve from 0.03136\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.0144 - accuracy: 0.9953 - val_loss: 0.0339 - val_accuracy: 0.9892 - lr: 1.0000e-06\n",
      "Epoch 62/100\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0143 - accuracy: 0.9954\n",
      "Epoch 62: val_loss did not improve from 0.03136\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.0143 - accuracy: 0.9954 - val_loss: 0.0341 - val_accuracy: 0.9892 - lr: 1.0000e-06\n",
      "Epoch 63/100\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.0142 - accuracy: 0.9954\n",
      "Epoch 63: val_loss did not improve from 0.03136\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.0142 - accuracy: 0.9954 - val_loss: 0.0341 - val_accuracy: 0.9892 - lr: 1.0000e-06\n",
      "Epoch 64/100\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.0141 - accuracy: 0.9955\n",
      "Epoch 64: val_loss did not improve from 0.03136\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.0141 - accuracy: 0.9955 - val_loss: 0.0341 - val_accuracy: 0.9892 - lr: 1.0000e-07\n",
      "Epoch 65/100\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0141 - accuracy: 0.9955\n",
      "Epoch 65: val_loss did not improve from 0.03136\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.0141 - accuracy: 0.9955 - val_loss: 0.0341 - val_accuracy: 0.9891 - lr: 1.0000e-07\n",
      "Epoch 66/100\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.0141 - accuracy: 0.9955\n",
      "Epoch 66: val_loss did not improve from 0.03136\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.0141 - accuracy: 0.9955 - val_loss: 0.0342 - val_accuracy: 0.9891 - lr: 1.0000e-07\n",
      "Epoch 67/100\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.0141 - accuracy: 0.9955\n",
      "Epoch 67: val_loss did not improve from 0.03136\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.0141 - accuracy: 0.9955 - val_loss: 0.0342 - val_accuracy: 0.9891 - lr: 1.0000e-07\n",
      "Epoch 68/100\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.0141 - accuracy: 0.9955\n",
      "Epoch 68: val_loss did not improve from 0.03136\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.0141 - accuracy: 0.9955 - val_loss: 0.0342 - val_accuracy: 0.9891 - lr: 1.0000e-08\n",
      "Epoch 69/100\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.0141 - accuracy: 0.9955\n",
      "Epoch 69: val_loss did not improve from 0.03136\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.0141 - accuracy: 0.9955 - val_loss: 0.0342 - val_accuracy: 0.9891 - lr: 1.0000e-08\n",
      "Epoch 70/100\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.0141 - accuracy: 0.9955\n",
      "Epoch 70: val_loss did not improve from 0.03136\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.0141 - accuracy: 0.9955 - val_loss: 0.0342 - val_accuracy: 0.9891 - lr: 1.0000e-08\n",
      "Epoch 71/100\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.0141 - accuracy: 0.9955\n",
      "Epoch 71: val_loss did not improve from 0.03136\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.0141 - accuracy: 0.9955 - val_loss: 0.0342 - val_accuracy: 0.9891 - lr: 1.0000e-08\n",
      "Epoch 72/100\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0141 - accuracy: 0.9955\n",
      "Epoch 72: val_loss did not improve from 0.03136\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.0141 - accuracy: 0.9955 - val_loss: 0.0342 - val_accuracy: 0.9891 - lr: 1.0000e-09\n",
      "Epoch 73/100\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0141 - accuracy: 0.9955\n",
      "Epoch 73: val_loss did not improve from 0.03136\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.0141 - accuracy: 0.9955 - val_loss: 0.0342 - val_accuracy: 0.9891 - lr: 1.0000e-09\n",
      "Epoch 74/100\n",
      "149/150 [============================>.] - ETA: 0s - loss: 0.0141 - accuracy: 0.9955\n",
      "Epoch 74: val_loss did not improve from 0.03136\n",
      "150/150 [==============================] - 15s 100ms/step - loss: 0.0141 - accuracy: 0.9955 - val_loss: 0.0342 - val_accuracy: 0.9891 - lr: 1.0000e-09\n",
      "Epoch 75/100\n",
      "150/150 [==============================] - ETA: 0s - loss: 0.0141 - accuracy: 0.9955\n",
      "Epoch 75: val_loss did not improve from 0.03136\n",
      "150/150 [==============================] - 15s 101ms/step - loss: 0.0141 - accuracy: 0.9955 - val_loss: 0.0342 - val_accuracy: 0.9891 - lr: 1.0000e-09\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb3101bbdf0>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_dataset, validation_data=valid_dataset, epochs=100, callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"UNET\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 128, 128, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 128, 128, 64  1792        ['input_3[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 128, 128, 64  256        ['conv2d_38[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 128, 128, 64  0           ['batch_normalization_36[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 128, 128, 64  36928       ['activation_36[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 128, 128, 64  256        ['conv2d_39[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 128, 128, 64  0           ['batch_normalization_37[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_8 (MaxPooling2D)  (None, 64, 64, 64)  0           ['activation_37[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 64, 64, 128)  73856       ['max_pooling2d_8[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 64, 64, 128)  512        ['conv2d_40[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (None, 64, 64, 128)  0           ['batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 64, 64, 128)  147584      ['activation_38[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 64, 64, 128)  512        ['conv2d_41[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_39 (Activation)     (None, 64, 64, 128)  0           ['batch_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_9 (MaxPooling2D)  (None, 32, 32, 128)  0          ['activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 32, 32, 512)  590336      ['max_pooling2d_9[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 32, 32, 512)  2048       ['conv2d_42[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_40 (Activation)     (None, 32, 32, 512)  0           ['batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 32, 32, 512)  2359808     ['activation_40[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 32, 32, 512)  2048       ['conv2d_43[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_41 (Activation)     (None, 32, 32, 512)  0           ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_10 (MaxPooling2D  (None, 16, 16, 512)  0          ['activation_41[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 16, 16, 512)  2359808     ['max_pooling2d_10[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 16, 16, 512)  2048       ['conv2d_44[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, 16, 16, 512)  0           ['batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 16, 16, 512)  2359808     ['activation_42[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 16, 16, 512)  2048       ['conv2d_45[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, 16, 16, 512)  0           ['batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " max_pooling2d_11 (MaxPooling2D  (None, 8, 8, 512)   0           ['activation_43[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 8, 8, 1024)   4719616     ['max_pooling2d_11[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 8, 8, 1024)  4096        ['conv2d_46[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, 8, 8, 1024)   0           ['batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 8, 8, 1024)   9438208     ['activation_44[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 8, 8, 1024)  4096        ['conv2d_47[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_45 (Activation)     (None, 8, 8, 1024)   0           ['batch_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_transpose_8 (Conv2DTran  (None, 16, 16, 512)  2097664    ['activation_45[0][0]']          \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate)    (None, 16, 16, 1024  0           ['conv2d_transpose_8[0][0]',     \n",
      "                                )                                 'activation_43[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 16, 16, 512)  4719104     ['concatenate_8[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 16, 16, 512)  2048       ['conv2d_48[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_46 (Activation)     (None, 16, 16, 512)  0           ['batch_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 16, 16, 512)  2359808     ['activation_46[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 16, 16, 512)  2048       ['conv2d_49[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_47 (Activation)     (None, 16, 16, 512)  0           ['batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_transpose_9 (Conv2DTran  (None, 32, 32, 256)  524544     ['activation_47[0][0]']          \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_9 (Concatenate)    (None, 32, 32, 768)  0           ['conv2d_transpose_9[0][0]',     \n",
      "                                                                  'activation_41[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 32, 32, 256)  1769728     ['concatenate_9[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_50[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_48 (Activation)     (None, 32, 32, 256)  0           ['batch_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, 32, 32, 256)  590080      ['activation_48[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 32, 32, 256)  1024       ['conv2d_51[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_49 (Activation)     (None, 32, 32, 256)  0           ['batch_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_transpose_10 (Conv2DTra  (None, 64, 64, 128)  131200     ['activation_49[0][0]']          \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate_10 (Concatenate)   (None, 64, 64, 256)  0           ['conv2d_transpose_10[0][0]',    \n",
      "                                                                  'activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, 64, 64, 128)  295040      ['concatenate_10[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 64, 64, 128)  512        ['conv2d_52[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_50 (Activation)     (None, 64, 64, 128)  0           ['batch_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, 64, 64, 128)  147584      ['activation_50[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 64, 64, 128)  512        ['conv2d_53[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_51 (Activation)     (None, 64, 64, 128)  0           ['batch_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_transpose_11 (Conv2DTra  (None, 128, 128, 64  32832      ['activation_51[0][0]']          \n",
      " nspose)                        )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_11 (Concatenate)   (None, 128, 128, 12  0           ['conv2d_transpose_11[0][0]',    \n",
      "                                8)                                'activation_37[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, 128, 128, 64  73792       ['concatenate_11[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 128, 128, 64  256        ['conv2d_54[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_52 (Activation)     (None, 128, 128, 64  0           ['batch_normalization_52[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, 128, 128, 64  36928       ['activation_52[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_53 (BatchN  (None, 128, 128, 64  256        ['conv2d_55[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_53 (Activation)     (None, 128, 128, 64  0           ['batch_normalization_53[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)             (None, 128, 128, 1)  65          ['activation_53[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 34,891,713\n",
      "Trainable params: 34,878,913\n",
      "Non-trainable params: 12,800\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "save_path= \"prediction,non-aug\"\n",
    "\n",
    "\n",
    "create_dir(save_path)\n",
    "\n",
    "model2=tf.keras.models.load_model(model_file)\n",
    "model2.summary()\n",
    "\n",
    "\n",
    "test_x=sorted(os.path.join(dataset_path, 'test', \"*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/keanuf/.cache/Assignemt9/BRAIN SEGMENTATION/dataset2/non-aug/test/images/0.png'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x=sorted(glob(os.path.join(\"/home/keanuf/.cache/Assignemt9/BRAIN SEGMENTATION/dataset2/non-aug/test\", \"images\",\"*\")))\n",
    "test_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/239 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.png\n",
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/239 [00:00<01:03,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.png\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "10.png\n",
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 3/239 [00:00<00:26,  8.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.png\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "101.png\n",
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 5/239 [00:00<00:19, 11.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102.png\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "103.png\n",
      "1/1 [==============================] - 0s 27ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 7/239 [00:00<00:16, 13.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104.png\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "105.png\n",
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 9/239 [00:00<00:15, 14.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106.png\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "107.png\n",
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 11/239 [00:00<00:14, 15.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108.png\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "109.png\n",
      "1/1 [==============================] - 0s 30ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 13/239 [00:00<00:14, 15.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.png\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "110.png\n",
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 15/239 [00:01<00:13, 16.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111.png\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "112.png\n",
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 17/239 [00:01<00:13, 16.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113.png\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "114.png\n",
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 19/239 [00:01<00:12, 17.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115.png\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "116.png\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 21/239 [00:01<00:11, 18.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117.png\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "118.png\n",
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 23/239 [00:01<00:11, 18.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119.png\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "12.png\n",
      "1/1 [==============================] - 0s 27ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 25/239 [00:01<00:12, 17.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120.png\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "121.png\n",
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 27/239 [00:01<00:12, 16.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122.png\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "123.png\n",
      "1/1 [==============================] - 0s 27ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 29/239 [00:01<00:12, 16.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124.png\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "125.png\n",
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 31/239 [00:02<00:14, 14.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126.png\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "127.png\n",
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 33/239 [00:02<00:14, 14.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128.png\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "129.png\n",
      "1/1 [==============================] - 0s 32ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 35/239 [00:02<00:13, 14.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.png\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "130.png\n",
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 37/239 [00:02<00:13, 15.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131.png\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "132.png\n",
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 39/239 [00:02<00:12, 15.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133.png\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "134.png\n",
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 41/239 [00:02<00:12, 15.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135.png\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "136.png\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 43/239 [00:02<00:12, 16.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137.png\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "138.png\n",
      "1/1 [==============================] - 0s 29ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 45/239 [00:02<00:11, 16.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139.png\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "14.png\n",
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 47/239 [00:03<00:11, 16.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140.png\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "141.png\n",
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 49/239 [00:03<00:11, 17.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142.png\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "143.png\n",
      "1/1 [==============================] - 0s 33ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 51/239 [00:03<00:11, 16.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144.png\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "145.png\n",
      "1/1 [==============================] - 0s 30ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 53/239 [00:03<00:11, 16.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146.png\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "147.png\n",
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 55/239 [00:03<00:11, 16.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148.png\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "149.png\n",
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 57/239 [00:03<00:11, 16.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.png\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "150.png\n",
      "1/1 [==============================] - 0s 30ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 59/239 [00:03<00:11, 16.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151.png\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "152.png\n",
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 61/239 [00:03<00:11, 16.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153.png\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "154.png\n",
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 63/239 [00:04<00:10, 16.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155.png\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "156.png\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 65/239 [00:04<00:10, 16.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157.png\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "158.png\n",
      "1/1 [==============================] - 0s 29ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 67/239 [00:04<00:10, 17.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159.png\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "16.png\n",
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 69/239 [00:04<00:09, 17.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160.png\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "161.png\n",
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 71/239 [00:04<00:10, 16.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162.png\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "163.png\n",
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 73/239 [00:04<00:09, 17.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164.png\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "165.png\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 75/239 [00:04<00:09, 17.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166.png\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "167.png\n",
      "1/1 [==============================] - 0s 41ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 77/239 [00:04<00:09, 16.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168.png\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "169.png\n",
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 79/239 [00:04<00:09, 16.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.png\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "170.png\n",
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 81/239 [00:05<00:09, 16.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171.png\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "172.png\n",
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 83/239 [00:05<00:09, 17.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173.png\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "174.png\n",
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 85/239 [00:05<00:08, 17.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175.png\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "176.png\n",
      "1/1 [==============================] - 0s 33ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 87/239 [00:05<00:09, 16.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177.png\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "178.png\n",
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 89/239 [00:05<00:09, 16.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179.png\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "18.png\n",
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 91/239 [00:05<00:09, 16.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180.png\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "181.png\n",
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 93/239 [00:05<00:08, 16.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182.png\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "183.png\n",
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 95/239 [00:05<00:08, 16.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184.png\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "185.png\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 97/239 [00:06<00:08, 16.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186.png\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "187.png\n",
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 99/239 [00:06<00:08, 16.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188.png\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "189.png\n",
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 101/239 [00:06<00:08, 16.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.png\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "190.png\n",
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 103/239 [00:06<00:08, 16.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191.png\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "192.png\n",
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 105/239 [00:06<00:08, 16.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193.png\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "194.png\n",
      "1/1 [==============================] - 0s 30ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 107/239 [00:06<00:08, 15.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195.png\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "196.png\n",
      "1/1 [==============================] - 0s 30ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 109/239 [00:06<00:08, 15.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197.png\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "198.png\n",
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 111/239 [00:06<00:08, 15.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199.png\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "2.png\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 113/239 [00:07<00:08, 15.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.png\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "200.png\n",
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 115/239 [00:07<00:07, 15.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201.png\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "202.png\n",
      "1/1 [==============================] - 0s 29ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 117/239 [00:07<00:07, 15.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203.png\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "204.png\n",
      "1/1 [==============================] - 0s 42ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 119/239 [00:07<00:08, 14.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205.png\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "206.png\n",
      "1/1 [==============================] - 0s 50ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 121/239 [00:07<00:10, 11.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207.png\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "208.png\n",
      "1/1 [==============================] - 0s 51ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 123/239 [00:07<00:10, 10.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209.png\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "21.png\n",
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 125/239 [00:08<00:09, 11.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210.png\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "211.png\n",
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 127/239 [00:08<00:08, 12.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212.png\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "213.png\n",
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 129/239 [00:08<00:08, 13.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214.png\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "215.png\n",
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 131/239 [00:08<00:08, 13.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216.png\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "217.png\n",
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 133/239 [00:08<00:07, 13.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218.png\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "219.png\n",
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 135/239 [00:08<00:07, 13.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.png\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "220.png\n",
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 137/239 [00:08<00:07, 13.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221.png\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "222.png\n",
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 139/239 [00:09<00:07, 14.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223.png\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "224.png\n",
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 141/239 [00:09<00:06, 14.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225.png\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "226.png\n",
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 143/239 [00:09<00:06, 14.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227.png\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "228.png\n",
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 145/239 [00:09<00:06, 14.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229.png\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "23.png\n",
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 147/239 [00:09<00:06, 14.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230.png\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "231.png\n",
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 149/239 [00:09<00:06, 14.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232.png\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "233.png\n",
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 151/239 [00:09<00:06, 14.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234.png\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "235.png\n",
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 153/239 [00:10<00:06, 14.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236.png\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "237.png\n",
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 155/239 [00:10<00:05, 14.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "238.png\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "24.png\n",
      "1/1 [==============================] - 0s 29ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 157/239 [00:10<00:06, 12.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.png\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "26.png\n",
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 159/239 [00:10<00:05, 13.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.png\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "28.png\n",
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 161/239 [00:10<00:05, 13.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.png\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "3.png\n",
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 163/239 [00:10<00:05, 13.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.png\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "31.png\n",
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 165/239 [00:10<00:05, 14.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.png\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "33.png\n",
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 167/239 [00:11<00:05, 13.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.png\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "35.png\n",
      "1/1 [==============================] - 0s 30ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 169/239 [00:11<00:05, 13.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.png\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "37.png\n",
      "1/1 [==============================] - 0s 27ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 171/239 [00:11<00:04, 13.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38.png\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "39.png\n",
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 173/239 [00:11<00:04, 13.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.png\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "40.png\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 175/239 [00:11<00:04, 14.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.png\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "42.png\n",
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 177/239 [00:11<00:04, 13.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.png\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "44.png\n",
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 179/239 [00:11<00:04, 13.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45.png\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "46.png\n",
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 181/239 [00:12<00:04, 14.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47.png\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "48.png\n",
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 183/239 [00:12<00:03, 14.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.png\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "5.png\n",
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 185/239 [00:12<00:03, 14.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.png\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "51.png\n",
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 187/239 [00:12<00:03, 13.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.png\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "53.png\n",
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 189/239 [00:12<00:03, 13.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.png\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "55.png\n",
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 191/239 [00:12<00:03, 13.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56.png\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "57.png\n",
      "1/1 [==============================] - 0s 27ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 193/239 [00:12<00:03, 13.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58.png\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "59.png\n",
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 195/239 [00:13<00:03, 13.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.png\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "60.png\n",
      "1/1 [==============================] - 0s 29ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 197/239 [00:13<00:03, 13.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61.png\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "62.png\n",
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 199/239 [00:13<00:02, 13.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63.png\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "64.png\n",
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 201/239 [00:13<00:02, 13.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.png\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "66.png\n",
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 203/239 [00:13<00:02, 13.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67.png\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "68.png\n",
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 205/239 [00:13<00:02, 13.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69.png\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "7.png\n",
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 207/239 [00:13<00:02, 13.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.png\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "71.png\n",
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 209/239 [00:14<00:02, 14.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.png\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "73.png\n",
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 211/239 [00:14<00:01, 14.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.png\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "75.png\n",
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 213/239 [00:14<00:01, 13.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76.png\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "77.png\n",
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 215/239 [00:14<00:01, 13.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78.png\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "79.png\n",
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 217/239 [00:14<00:01, 13.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.png\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "80.png\n",
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 219/239 [00:14<00:01, 13.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.png\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "82.png\n",
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 221/239 [00:15<00:01, 13.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83.png\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "84.png\n",
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 223/239 [00:15<00:01, 13.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.png\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "86.png\n",
      "1/1 [==============================] - 0s 27ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 225/239 [00:15<00:01, 12.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87.png\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "88.png\n",
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 227/239 [00:15<00:00, 12.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.png\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "9.png\n",
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 229/239 [00:15<00:00, 12.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.png\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "91.png\n",
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 231/239 [00:15<00:00, 12.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92.png\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "93.png\n",
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 233/239 [00:15<00:00, 12.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.png\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "95.png\n",
      "1/1 [==============================] - 0s 30ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 235/239 [00:16<00:00,  7.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.png\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "97.png\n",
      "1/1 [==============================] - 0s 32ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 237/239 [00:16<00:00,  8.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.png\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "99.png\n",
      "1/1 [==============================] - 0s 36ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 239/239 [00:16<00:00, 14.18it/s]\n"
     ]
    }
   ],
   "source": [
    "time_taken=[]\n",
    "import time\n",
    "for x in tqdm(test_x):\n",
    "    name=x.split(\"/\")[-1]\n",
    "    print(name)\n",
    "    x= cv2.imread(x ,cv2.IMREAD_COLOR)\n",
    "    x=x / 255.0\n",
    "    x=np.expand_dims(x,axis=0)\n",
    "    start_time=time.time()\n",
    "    p= model.predict(x)[0]\n",
    "    total_time=time.time()-start_time\n",
    "    time_taken.append(total_time)\n",
    "    p=p>0.5\n",
    "    p=p*255\n",
    "    cv2.imwrite(os.path.join(save_path, name),p)\n",
    "\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def composite_images(image_folder, mask_folder, output_folder):\n",
    "    # Get the list of image files in the input folder\n",
    "    image_files = os.listdir(image_folder)\n",
    "    \n",
    "    # Iterate through each image file\n",
    "    for image_file in image_files:\n",
    "        # Construct the file paths for the current image and its corresponding mask\n",
    "        image_path = os.path.join(image_folder, image_file)\n",
    "        mask_file = image_file.split('.')[0] + '.png'  # Assuming masks have the same filename format as images\n",
    "        mask_path = os.path.join(mask_folder, mask_file)\n",
    "        \n",
    "        # Open the image and mask\n",
    "        image = Image.open(image_path)\n",
    "        mask = Image.open(mask_path)\n",
    "        \n",
    "        # Perform composite operation\n",
    "        result = Image.composite(image, Image.new('RGB', image.size, (0, 0, 0)), mask)\n",
    "        \n",
    "        # Construct the output file path\n",
    "        output_file = os.path.join(output_folder, image_file)\n",
    "        \n",
    "        # Save the resulting composite image\n",
    "        result.save(output_file)\n",
    "\n",
    "# Paths to input image and mask folders, and output folder\n",
    "image_folder = '/home/keanuf/.cache/Assignemt9/BRAIN SEGMENTATION/dataset2/non-aug/test/images'\n",
    "mask_folder = '/home/keanuf/.cache/Assignemt9/BRAIN SEGMENTATION/prediction,non-aug'\n",
    "output_folder = '/home/keanuf/.cache/BRAIN SEGMENTATOIN'\n",
    "\n",
    "# Call the function to composite images and masks and save the results\n",
    "composite_images(image_folder, mask_folder, output_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
