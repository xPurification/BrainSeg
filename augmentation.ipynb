{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np \n",
    "import cv2\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from albumentations import HorizontalFlip, CoarseDropout, RandomBrightnessContrast, RandomRotate90\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path):\n",
    "    images = sorted(glob(os.path.jion(path, \"images\", \"*\")))\n",
    "    masks = sorted(glob(os.path.jion(path, \"masks\", \"*\")))\n",
    "    return images, masks\n",
    "\n",
    "dataset_path = os.path.join(\"dataset2\", \"non-aug\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(inputs, num_filters):\n",
    "    x= Conv2D(num_filters, 3, padding=\"same\")(inputs)\n",
    "    x= BatchNormalization()(x)\n",
    "    x=Activation('relu')(x)\n",
    "\n",
    "    x=Conv2D(num_filters, 3, padding=\"same\")(x)\n",
    "    x=BatchNormalization()(x)\n",
    "    x=Activation(\"relu\")(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataset(images, masks, save_dir, augment=False):\n",
    "    for x, y in tqdm(zip(images, masks), total=len(images)):\n",
    "        name= x.split(\"/\")[-1].split(\".\")[0]\n",
    "        x= cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "        y=cv2.imread(y,cv2.IMREAD_COLOR)\n",
    "        if augment == True:\n",
    "            aug= HorizontalFlip(p=1)\n",
    "            augmented = aug(image=x, mask=y)\n",
    "            x1= augmented[\"image\"]\n",
    "            y1= augmented[\"mask\"]\n",
    "\n",
    "            aug= CoarseDropout(p=1, max_hole=10, max_height=8, max_width=8)\n",
    "            augmented= aug(image=x, mask=y)\n",
    "            x2=augmented['image']\n",
    "            y2= augmented['mask']\n",
    "\n",
    "            aug= RandomBrightnessContrast(p=1)\n",
    "            augmented= aug(image=x, mask=y)\n",
    "            x3=augmented['image']\n",
    "            y3= augmented['mask']\n",
    "\n",
    "            aug_x = [x, x1, x2, x3]\n",
    "            aug_y = [y, y1, y2,y3]\n",
    "        else:\n",
    "            aug_x=[x]\n",
    "            aug_y=[y]\n",
    "        idx=0\n",
    "        for ax , ay in zip(aug_x, aug_y):\n",
    "            aug_name=f\"{name}_{idx}.png\"\n",
    "            save_image_path= os.path.join(save_dir, \"images\", aug_name)\n",
    "            save_mask_path = os.path.join(save_dir,\"masks\", aug_name)\n",
    "\n",
    "            cv2.imwrite(save_image_path, ax)\n",
    "            cv2.imwrite(save_mask_path, ay)\n",
    "\n",
    "            idx +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = os.path.join(\"dataset2\", \"non-aug\")\n",
    "for item in [\"train\", \"valid\", \"test\"]:\n",
    "    create_dir(os.path.join(save_dir, item, \"images\"))\n",
    "    create_dir(os.path.join(save_dir, item, \"masks\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    train_x= sorted(glob(os.path.join(path, \"train\", \"images\", \"*\" )))\n",
    "    train_y= sorted(glob(os.path.join(path, \"train\", \"masks\", \"*\" )))\n",
    "    valid_x= sorted(glob(os.path.join(path, \"valid\", \"images\", \"*\" )))\n",
    "    valid_y= sorted(glob(os.path.join(path, \"valid\", \"masks\", \"*\" )))\n",
    "\n",
    "    return (train_x, train_y), (valid_x, valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 239 239\n",
      "valid 1542 1542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 239/239 [00:00<00:00, 256.71it/s]\n",
      "100%|██████████| 1542/1542 [00:05<00:00, 277.39it/s]\n"
     ]
    }
   ],
   "source": [
    "(train_x, train_y), (valid_x, valid_y)= load_data(dataset_path)\n",
    "\n",
    "print(\"train\" , len(train_x), len(train_y))\n",
    "print(\"valid\" , len(valid_x), len(valid_y))\n",
    "\n",
    "save_dataset(train_x, train_y, os.path.join(save_dir, \"train\"), augment=True)\n",
    "save_dataset(valid_x, valid_y, os.path.join(save_dir, \"valid\"), augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
